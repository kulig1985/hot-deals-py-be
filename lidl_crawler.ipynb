{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11f1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from configparser import ConfigParser\n",
    "import unidecode\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9d8c3",
   "metadata": {},
   "source": [
    "# get all lidl offer url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afe5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_link_lidl():\n",
    "    \n",
    "    offer_page = 'https://www.lidl.hu/ajanlataink'\n",
    "    \n",
    "    page = urllib.request.urlopen(offer_page)\n",
    "    soup = bs(page)\n",
    "    \n",
    "    divs_body = soup.body.findAll('div', {'class' : ['tabnavaccordion__content']})\n",
    "\n",
    "    all_link = []\n",
    "    for div in divs_body:\n",
    "        for a in div.find_all('a', href=True):\n",
    "            url = 'https://www.lidl.hu' + a['href']\n",
    "            #print(url)\n",
    "            all_link.append(url)\n",
    "            \n",
    "    return all_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d1137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_link = get_all_link_lidl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8658738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_offer_lidl(all_link):\n",
    "    \n",
    "    def find_nth_occurrence(string, char, occurrence):\n",
    "\n",
    "        val = -1\n",
    "        for i in range(0, occurrence):\n",
    "            val = string.find(char, val + 1)\n",
    "        return val\n",
    "\n",
    "    all_items = []\n",
    "    \n",
    "    counter = 1\n",
    "\n",
    "    for url in all_link:\n",
    "\n",
    "        print(f'crawl url: {url} done {counter} from {len(all_link)}')\n",
    "        counter = counter + 1\n",
    "\n",
    "        page = urllib.request.urlopen(url)\n",
    "        soup = bs(page)\n",
    "\n",
    "        divs = soup.body.findAll('div', {'class' : ['nuc-a-flex-item']})\n",
    "\n",
    "        for div in divs:\n",
    "            articles = div.findAll('article', {'class' : 'ret-o-card'})\n",
    "            for article in articles:\n",
    "\n",
    "                item_dict = {}\n",
    "\n",
    "                #print(article['data-id'])\n",
    "                item_dict['itemId'] = article['data-id']\n",
    "\n",
    "                #print(article['data-name'])\n",
    "                brand = article.find('p', {'class' : 'ret-o-card__content'})\n",
    "\n",
    "                if brand != None:\n",
    "                    #print(brand.get_text().strip())\n",
    "                    item_dict['itemName'] = article['data-name'] + ' - ' + brand.get_text().strip()\n",
    "                else:\n",
    "                    item_dict['itemName'] = article['data-name']\n",
    "                    \n",
    "                item_dict['itemCleanName'] = unidecode.unidecode(item_dict['itemName']).lower()\n",
    "\n",
    "                #print(article['data-price'])\n",
    "                item_dict['price'] = article['data-price']\n",
    "                \n",
    "                measure = article.find('div', {'class' : 'lidl-m-pricebox__basic-quantity'})\n",
    "                \n",
    "                if measure != None:\n",
    "                    item_dict['measure'] = measure.get_text()\n",
    "                else:\n",
    "                    item_dict['measure'] = np.nan\n",
    "\n",
    "                #print(article['data-list'])\n",
    "\n",
    "                sales_from_pattern = r'(?P<group_1>[\\d]{2}.[\\d]{2})'\n",
    "\n",
    "                if (article['data-list'] != None) and (re.search(sales_from_pattern, article['data-list']) != None):\n",
    "\n",
    "                    sales_data = article['data-list']\n",
    "                    item_dict['salesStart'] = str(datetime.now().year) + '.' + re.search(sales_from_pattern,\n",
    "                                                                                          article['data-list'])[0]\n",
    "                else:\n",
    "                    item_dict['salesStart'] = np.nan\n",
    "\n",
    "                cut_url = url[find_nth_occurrence(url, '/', 4)+1:]\n",
    "\n",
    "                item_dict['source'] = cut_url[:cut_url.find('/')]\n",
    "                item_dict['runDate'] = datetime.now().strftime('%Y.%m.%d-%H:%M:%S')\n",
    "                item_dict['shopName'] = 'lidl'\n",
    "\n",
    "                if len(item_dict) > 0:\n",
    "                    all_items.append(item_dict)\n",
    "\n",
    "                #print('-----')\n",
    "\n",
    "    df = pd.DataFrame(all_items)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a0511b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawl url: https://www.lidl.hu/c/akcioink-06-23-csutortoktol/c3505/w1 done 1 from 20\n",
      "crawl url: https://www.lidl.hu/c/jegkrem-ajanlataink/c3508/w1 done 2 from 20\n",
      "crawl url: https://www.lidl.hu/c/noi-ferfi-divat/c3513/w1 done 3 from 20\n",
      "crawl url: https://www.lidl.hu/c/ajanlataink-sportolashoz/c3514/w1 done 4 from 20\n",
      "crawl url: https://www.lidl.hu/c/virag-ajanlataink-06-27-hetfotol/c3517/w1 done 5 from 20\n",
      "crawl url: https://www.lidl.hu/c/xxl-ajanlataink/c3518/w1 done 6 from 20\n",
      "crawl url: https://www.lidl.hu/c/kreativ-es-hobbi-ajanlataink/c3515/w1 done 7 from 20\n",
      "crawl url: https://www.lidl.hu/c/akcioink-06-27-hetfotol/c3516/w1 done 8 from 20\n",
      "crawl url: https://www.lidl.hu/c/akcioink-06-30-csutortoktol/c3519/w1 done 9 from 20\n",
      "crawl url: https://www.lidl.hu/c/zoldseg-gyumolcs-akcioink-06-30-csutortoktol/c3520/w1 done 10 from 20\n",
      "crawl url: https://www.lidl.hu/c/virag-ajanlataink-06-30-csutortoktol/c3521/w1 done 11 from 20\n",
      "crawl url: https://www.lidl.hu/c/konyhai-es-haztartasi-ajanlataink/c3522/w1 done 12 from 20\n",
      "crawl url: https://www.lidl.hu/c/noi-ferfi-divat/c3523/w1 done 13 from 20\n",
      "crawl url: https://www.lidl.hu/c/szuper-hetvege-07-02-szombattol/c3524/w1 done 14 from 20\n",
      "crawl url: https://www.lidl.hu/c/akcioink-06-30-csutortoktol/c3519/w2 done 15 from 20\n",
      "crawl url: https://www.lidl.hu/c/strand-es-kemping-ajanlataink/c3525/w2 done 16 from 20\n",
      "crawl url: https://www.lidl.hu/c/kertapolasi-es-dekoracios-ajanlataink/c3526/w2 done 17 from 20\n",
      "crawl url: https://www.lidl.hu/c/akcioink-07-04-hetfotol/c3527/w2 done 18 from 20\n",
      "crawl url: https://www.lidl.hu/c/virag-ajanlataink-07-04-hetfotol/c3528/w2 done 19 from 20\n",
      "crawl url: https://www.lidl.hu/c/olasz-izvilag-inspiralta-inyencsegek/c3529/w2 done 20 from 20\n"
     ]
    }
   ],
   "source": [
    "df = get_all_offer_lidl(all_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557aa233",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('N.a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1060cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('lidl_result.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c0d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4866015e",
   "metadata": {},
   "source": [
    "# backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e88e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7501bb30",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c0/h6vkq2vn7h95_l8mlxd7qtrh0000gn/T/ipykernel_97377/2728769195.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdivs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'nuc-a-flex-item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdiv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdivs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "all_items = []\n",
    "\n",
    "divs = soup.body.findAll('div', {'class' : ['nuc-a-flex-item']})\n",
    "\n",
    "for div in divs:\n",
    "    articles = div.findAll('article', {'class' : 'ret-o-card'})\n",
    "    for article in articles:\n",
    "            \n",
    "            item_dict = {}\n",
    "            \n",
    "            #print(article['data-id'])\n",
    "            item_dict['item_id'] = article['data-id']\n",
    "            \n",
    "            #print(article['data-name'])\n",
    "            brand = article.find('p', {'class' : 'ret-o-card__content'})\n",
    "            \n",
    "            if brand != None:\n",
    "                #print(brand.get_text().strip())\n",
    "                item_dict['item_name'] = article['data-name'] + ' - ' + brand.get_text().strip()\n",
    "            else:\n",
    "                item_dict['item_name'] = article['data-name']\n",
    "            \n",
    "            #print(article['data-price'])\n",
    "            item_dict['price'] = article['data-price']\n",
    "            \n",
    "            item_dict['measure'] = np.nan\n",
    "            \n",
    "            #print(article['data-list'])\n",
    "            \n",
    "            sales_from_pattern = r'(?P<group_1>[\\d]{2}.[\\d]{2})'\n",
    "            \n",
    "            if (article['data-list'] != None) and (re.search(sales_from_pattern, article['data-list']) != None):\n",
    "            \n",
    "                sales_data = article['data-list']\n",
    "                item_dict['sales_start'] = str(datetime.now().year) + '.' + re.search(sales_from_pattern,\n",
    "                                                                                      article['data-list'])[0]\n",
    "            else:\n",
    "                item_dict['sales_start'] = np.nan\n",
    "                \n",
    "            cut_url = url[find_nth_occurrence(url, '/', 4)+1:]\n",
    "            \n",
    "            item_dict['source'] = cut_url[:cut_url.find('/')]\n",
    "            item_dict['run_date'] = datetime.now().strftime('%Y.%m.%d-%H:%M:%S')\n",
    "            \n",
    "            if len(item_dict) > 0:\n",
    "                all_items.append(item_dict)\n",
    "            \n",
    "            #print('-----')\n",
    "\n",
    "df = pd.DataFrame(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c577d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29ba85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
